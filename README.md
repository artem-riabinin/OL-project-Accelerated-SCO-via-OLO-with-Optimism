We compare the performance of AccelPDA, UniAdaGrad ([1]) for two different tasks against some other well-known adaptive methods, such as AdaGrad ([2]) and UniXGrad ([3]).
We consider a synthetic setting where we analyze the convergence behavior (Problem 1, Least Squares Problem), as well as a SVM classification task on some LIBSVM dataset (Problem 2, Logistic Regression Problem).

[1] Pooria Joulani, Anant Raj, Andras Gyorgy, and Csaba Szepesvari. A Simpler Approach to Accelerated Stochastic Optimization: Iterative Averaging Meets Optimism. In Proceedings of the 37th
International Conference on Machine Learning, 2020.

[2] K. Levy. Online to offline conversions, universality and adaptive minibatch sizes. In Advances in Neural Information Processing Systems, pages 1612â€“1621, 2017.

[3] Ali Kavis, Kfir Y. Levy, Francis Bach, and Volkan Cevher. UniXGrad: A Universal, Adaptive Algorithm with Optimal Guarantees for Constrained Optimization. In Advances in Neural Information Processing Systems 32, 2020.
